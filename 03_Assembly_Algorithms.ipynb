{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4927f1e",
   "metadata": {},
   "source": [
    "# Genome Assembly: 3. De Novo Assembly Algorithms\n",
    "\n",
    "## Overview\n",
    "This notebook implements the core assembly algorithms from scratch:\n",
    "\n",
    "1. **Greedy Overlap-Based Assembly**: Simple but fast; can produce suboptimal results\n",
    "2. **De Bruijn Graph Assembly**: Optimized approach using k-mers (what modern assemblers use)\n",
    "\n",
    "We'll implement both to show the algorithmic trade-offs and why the De Bruijn approach is superior.\n",
    "\n",
    "**Data**: Uses reads from previous notebook (or generates synthetic ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bece4b",
   "metadata": {},
   "source": [
    "## 1. Greedy Overlap Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43635dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, deque\n",
    "from typing import List, Tuple, Set, Dict, Optional\n",
    "import time\n",
    "\n",
    "def calculate_overlap(seq1: str, seq2: str, min_overlap: int = 20) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Calculate the overlap length between the end of seq1 and the beginning of seq2.\n",
    "    \n",
    "    Returns: (overlap_length, num_mismatches)\n",
    "    \"\"\"\n",
    "    max_overlap = min(len(seq1), len(seq2))\n",
    "    best_overlap = 0\n",
    "    best_mismatches = float('inf')\n",
    "    \n",
    "    for overlap_len in range(max_overlap, min_overlap - 1, -1):\n",
    "        # Check how well seq1's suffix matches seq2's prefix\n",
    "        mismatches = 0\n",
    "        for i in range(overlap_len):\n",
    "            if seq1[-(overlap_len - i)] != seq2[i]:\n",
    "                mismatches += 1\n",
    "        \n",
    "        # Allow up to 5% mismatches\n",
    "        if mismatches / overlap_len <= 0.05:\n",
    "            best_overlap = overlap_len\n",
    "            best_mismatches = mismatches\n",
    "            break\n",
    "    \n",
    "    return best_overlap, best_mismatches\n",
    "\n",
    "def merge_reads(seq1: str, seq2: str, overlap: int) -> str:\n",
    "    \"\"\"\n",
    "    Merge two reads that overlap.\n",
    "    Concatenates seq1 + non-overlapping part of seq2.\n",
    "    \"\"\"\n",
    "    if overlap == 0:\n",
    "        return seq1 + seq2\n",
    "    return seq1 + seq2[overlap:]\n",
    "\n",
    "class GreedyAssembler:\n",
    "    \"\"\"\n",
    "    Simple greedy overlap-based assembler.\n",
    "    Algorithm:\n",
    "    1. Find best overlap between all read pairs\n",
    "    2. Greedily merge reads with highest overlap\n",
    "    3. Repeat until no more merges possible\n",
    "    \n",
    "    Pros: Simple, fast for small genomes\n",
    "    Cons: Can produce incorrect assemblies due to repeats, doesn't use all information\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, min_overlap: int = 20):\n",
    "        self.min_overlap = min_overlap\n",
    "        self.contigs = []\n",
    "    \n",
    "    def assemble(self, reads: List[str], max_iterations: int = 100) -> List[str]:\n",
    "        \"\"\"\n",
    "        Assemble reads using greedy overlap approach.\n",
    "        \"\"\"\n",
    "        # Start with all reads as single-read contigs\n",
    "        contigs = reads.copy()\n",
    "        iteration = 0\n",
    "        \n",
    "        while iteration < max_iterations:\n",
    "            # Find best pair of contigs to merge\n",
    "            best_pair = None\n",
    "            best_overlap = 0\n",
    "            \n",
    "            # Check all pairs\n",
    "            for i in range(len(contigs)):\n",
    "                for j in range(len(contigs)):\n",
    "                    if i == j:\n",
    "                        continue\n",
    "                    \n",
    "                    overlap, mismatches = calculate_overlap(contigs[i], contigs[j], self.min_overlap)\n",
    "                    \n",
    "                    if overlap > best_overlap:\n",
    "                        best_overlap = overlap\n",
    "                        best_pair = (i, j, overlap)\n",
    "            \n",
    "            # If no good merge found, we're done\n",
    "            if best_pair is None:\n",
    "                break\n",
    "            \n",
    "            # Merge the best pair\n",
    "            i, j, overlap = best_pair\n",
    "            merged = merge_reads(contigs[i], contigs[j], overlap)\n",
    "            \n",
    "            # Remove old contigs and add merged one\n",
    "            new_contigs = [contigs[k] for k in range(len(contigs)) if k not in (i, j)]\n",
    "            new_contigs.append(merged)\n",
    "            contigs = new_contigs\n",
    "            \n",
    "            iteration += 1\n",
    "        \n",
    "        self.contigs = contigs\n",
    "        return contigs\n",
    "\n",
    "# Test greedy assembly\n",
    "test_sequence = \"ATGCGATCGATCGATCG\" * 5\n",
    "test_reads = [\n",
    "    test_sequence[0:30],\n",
    "    test_sequence[15:45],\n",
    "    test_sequence[30:60],\n",
    "    test_sequence[45:75],\n",
    "    test_sequence[60:90],\n",
    "    test_sequence[75:105],\n",
    "]\n",
    "\n",
    "print(\"Test reads (with overlaps):\")\n",
    "for i, read in enumerate(test_reads):\n",
    "    print(f\"  {i}: {read}\")\n",
    "\n",
    "print(f\"\\nOriginal test sequence ({len(test_sequence)} bp):\")\n",
    "print(f\"  {test_sequence}\")\n",
    "\n",
    "greedy = GreedyAssembler(min_overlap=15)\n",
    "greedy_contigs = greedy.assemble(test_reads)\n",
    "\n",
    "print(f\"\\nGreedy assembly result ({len(greedy_contigs)} contigs):\")\n",
    "for i, contig in enumerate(greedy_contigs):\n",
    "    print(f\"  Contig {i} ({len(contig)} bp): {contig}\")\n",
    "    match = \"✓ MATCHES\" if contig in test_sequence else \"✗ doesn't match\"\n",
    "    print(f\"             {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc83697f",
   "metadata": {},
   "source": [
    "## 2. De Bruijn Graph Assembly (Optimized)\n",
    "\n",
    "**Why De Bruijn?**\n",
    "- More efficient: O(n) instead of O(n²) pairwise comparisons\n",
    "- Handles repeats better: Explicit branching points\n",
    "- Produces unambiguous regions as contigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f915805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeBruijnGraph:\n",
    "    \"\"\"\n",
    "    De Bruijn graph for assembly.\n",
    "    - Nodes: (k-1)-mers\n",
    "    - Edges: k-mers connecting (k-1)-mers\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k: int):\n",
    "        self.k = k\n",
    "        self.edges = defaultdict(lambda: defaultdict(int))  # edges[prefix][base] = count\n",
    "        self.in_degree = defaultdict(int)   # in-degree per node\n",
    "        self.out_degree = defaultdict(int)  # out-degree per node\n",
    "    \n",
    "    def add_sequence(self, sequence: str):\n",
    "        \"\"\"\n",
    "        Add all k-mers from a sequence to the graph.\n",
    "        \"\"\"\n",
    "        for i in range(len(sequence) - self.k + 1):\n",
    "            kmer = sequence[i:i + self.k]\n",
    "            prefix = kmer[:-1]\n",
    "            suffix = kmer[1:]\n",
    "            base = kmer[-1]\n",
    "            \n",
    "            self.edges[prefix][base] += 1\n",
    "            self.out_degree[prefix] += 1\n",
    "            self.in_degree[suffix] += 1\n",
    "    \n",
    "    def get_nodes(self) -> Set[str]:\n",
    "        \"\"\"Get all (k-1)-mers that are nodes in the graph.\"\"\"\n",
    "        nodes = set(self.edges.keys())\n",
    "        for suffix in self.in_degree.keys():\n",
    "            nodes.add(suffix)\n",
    "        return nodes\n",
    "    \n",
    "    def get_coverage(self, node: str) -> int:\n",
    "        \"\"\"Get the coverage (sum of edge weights) for a node.\"\"\"\n",
    "        return sum(self.edges[node].values())\n",
    "    \n",
    "    def simplify(self, min_coverage: int = 1):\n",
    "        \"\"\"\n",
    "        Remove low-coverage nodes (likely errors).\n",
    "        This is error correction.\n",
    "        \"\"\"\n",
    "        nodes_to_remove = []\n",
    "        for node in self.get_nodes():\n",
    "            coverage = self.get_coverage(node)\n",
    "            if coverage < min_coverage:\n",
    "                nodes_to_remove.append(node)\n",
    "        \n",
    "        for node in nodes_to_remove:\n",
    "            # Remove outgoing edges\n",
    "            if node in self.edges:\n",
    "                del self.edges[node]\n",
    "            \n",
    "            # Remove incoming edges\n",
    "            for prefix in self.edges:\n",
    "                if node in self.edges[prefix]:\n",
    "                    del self.edges[prefix][node]\n",
    "\n",
    "class DeBruijnAssembler:\n",
    "    \"\"\"\n",
    "    Modern De Bruijn graph-based assembler.\n",
    "    Implements contig extraction from the graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k: int = 21):\n",
    "        self.k = k\n",
    "        self.graph = DeBruijnGraph(k)\n",
    "    \n",
    "    def assemble(self, reads: List[str], min_coverage: int = 2) -> List[str]:\n",
    "        \"\"\"\n",
    "        Assemble reads using De Bruijn graph approach.\n",
    "        Returns contigs (unambiguous paths).\n",
    "        \"\"\"\n",
    "        # Build graph from reads\n",
    "        for read in reads:\n",
    "            self.graph.add_sequence(read)\n",
    "        \n",
    "        # Error correction: remove low-coverage edges\n",
    "        self.graph.simplify(min_coverage)\n",
    "        \n",
    "        # Extract contigs\n",
    "        contigs = self.extract_contigs()\n",
    "        \n",
    "        return contigs\n",
    "    \n",
    "    def extract_contigs(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extract linear contigs from the De Bruijn graph.\n",
    "        A contig is a path with in-degree = out-degree = 1 at internal nodes.\n",
    "        \"\"\"\n",
    "        contigs = []\n",
    "        visited_edges = set()\n",
    "        \n",
    "        # Find all starting points (in-degree = 0 or in-degree ≠ out-degree)\n",
    "        nodes = self.graph.get_nodes()\n",
    "        \n",
    "        for start_node in nodes:\n",
    "            out_deg = self.graph.out_degree[start_node]\n",
    "            in_deg = self.graph.in_degree[start_node]\n",
    "            \n",
    "            # Try to extend from this node\n",
    "            if out_deg > 0:  # Can go somewhere\n",
    "                for next_base in self.graph.edges[start_node]:\n",
    "                    if (start_node, next_base) in visited_edges:\n",
    "                        continue\n",
    "                    \n",
    "                    # Trace a path from here\n",
    "                    path = self._trace_path(start_node, next_base, visited_edges)\n",
    "                    if path:\n",
    "                        contig = self._path_to_sequence(start_node, path)\n",
    "                        contigs.append(contig)\n",
    "        \n",
    "        return contigs\n",
    "    \n",
    "    def _trace_path(self, start: str, first_base: str, visited: Set) -> List[str]:\n",
    "        \"\"\"\n",
    "        Trace a linear path through the graph.\n",
    "        Returns list of bases (edges).\n",
    "        \"\"\"\n",
    "        path = [first_base]\n",
    "        current = start[1:] + first_base  # New node: suffix of start + new base\n",
    "        visited.add((start, first_base))\n",
    "        \n",
    "        # Continue while path is unambiguous\n",
    "        while len(self.graph.edges[current]) == 1:\n",
    "            # Get the only outgoing edge\n",
    "            next_base = list(self.graph.edges[current].keys())[0]\n",
    "            \n",
    "            # Check if we've created a cycle (infinite loop)\n",
    "            if (current, next_base) in visited:\n",
    "                break\n",
    "            \n",
    "            path.append(next_base)\n",
    "            visited.add((current, next_base))\n",
    "            current = current[1:] + next_base\n",
    "        \n",
    "        return path\n",
    "    \n",
    "    def _path_to_sequence(self, start: str, path: List[str]) -> str:\n",
    "        \"\"\"\n",
    "        Convert a path (list of bases) to a sequence.\n",
    "        \"\"\"\n",
    "        return start + ''.join(path)\n",
    "\n",
    "# Test De Bruijn assembly\n",
    "print(\"De Bruijn Graph Assembly Test\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "db_assembler = DeBruijnAssembler(k=15)\n",
    "db_contigs = db_assembler.assemble(test_reads, min_coverage=1)\n",
    "\n",
    "print(f\"De Bruijn assembly result ({len(db_contigs)} contigs):\")\n",
    "for i, contig in enumerate(db_contigs):\n",
    "    print(f\"  Contig {i} ({len(contig)} bp): {contig}\")\n",
    "    match = \"✓ MATCHES\" if contig in test_sequence else \"✗ doesn't match\"\n",
    "    print(f\"             {match}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0be8b5",
   "metadata": {},
   "source": [
    "## 3. Comparison on Realistic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2490330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reads_from_sequence(sequence: str, read_length: int = 100, coverage: int = 10, \n",
    "                                 error_rate: float = 0.01, seed: int = 42) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate reads from a sequence with controlled coverage and error rate.\n",
    "    \"\"\"\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    num_reads = (len(sequence) * coverage) // read_length\n",
    "    reads = []\n",
    "    bases = ['A', 'T', 'G', 'C']\n",
    "    \n",
    "    for _ in range(num_reads):\n",
    "        # Random position\n",
    "        start = random.randint(0, max(0, len(sequence) - read_length))\n",
    "        read = sequence[start:start + read_length]\n",
    "        \n",
    "        # Introduce errors\n",
    "        read_list = list(read)\n",
    "        for i in range(len(read_list)):\n",
    "            if random.random() < error_rate:\n",
    "                read_list[i] = random.choice([b for b in bases if b != read_list[i]])\n",
    "        \n",
    "        reads.append(''.join(read_list))\n",
    "    \n",
    "    return reads\n",
    "\n",
    "# Generate a test genome with some repeats\n",
    "base = \"ATGCGATCGATCGATCGATCG\"\n",
    "test_genome = (base * 20) + (base * 5)  # One region is duplicated\n",
    "print(f\"Test genome: {len(test_genome)} bp (with one repeat region)\\n\")\n",
    "\n",
    "# Generate reads\n",
    "test_reads_large = generate_reads_from_sequence(test_genome, read_length=100, coverage=10, error_rate=0.005)\n",
    "print(f\"Generated {len(test_reads_large)} reads from test genome\")\n",
    "\n",
    "# Benchmark both assemblers\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BENCHMARK: Greedy vs De Bruijn Assembly\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Greedy\n",
    "print(\"\\n1. Greedy Overlap-Based Assembly\")\n",
    "start_time = time.time()\n",
    "greedy_large = GreedyAssembler(min_overlap=15)\n",
    "greedy_contigs_large = greedy_large.assemble(test_reads_large[:500], max_iterations=50)  # Limit for speed\n",
    "greedy_time = time.time() - start_time\n",
    "\n",
    "greedy_total_bp = sum(len(c) for c in greedy_contigs_large)\n",
    "print(f\"   Time: {greedy_time:.3f}s\")\n",
    "print(f\"   Contigs: {len(greedy_contigs_large)}\")\n",
    "print(f\"   Total assembled: {greedy_total_bp} bp\")\n",
    "\n",
    "# De Bruijn\n",
    "print(\"\\n2. De Bruijn Graph Assembly\")\n",
    "start_time = time.time()\n",
    "db_large = DeBruijnAssembler(k=21)\n",
    "db_contigs_large = db_large.assemble(test_reads_large, min_coverage=2)\n",
    "db_time = time.time() - start_time\n",
    "\n",
    "db_total_bp = sum(len(c) for c in db_contigs_large)\n",
    "print(f\"   Time: {db_time:.3f}s\")\n",
    "print(f\"   Contigs: {len(db_contigs_large)}\")\n",
    "print(f\"   Total assembled: {db_total_bp} bp\")\n",
    "\n",
    "print(f\"\\n3. Comparison\")\n",
    "print(f\"   De Bruijn is {greedy_time/db_time:.1f}x faster\")\n",
    "print(f\"   De Bruijn assembled {db_total_bp} bp vs Greedy {greedy_total_bp} bp\")\n",
    "print(f\"   Reference length: {len(test_genome)} bp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02c7c29",
   "metadata": {},
   "source": [
    "## 4. Error Correction in De Bruijn Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_error_correction_effect(reads: List[str], k: int = 21):\n",
    "    \"\"\"\n",
    "    Show how different coverage thresholds affect error correction.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for min_cov in [1, 2, 3, 5, 10]:\n",
    "        assembler = DeBruijnAssembler(k=k)\n",
    "        contigs = assembler.assemble(reads, min_coverage=min_cov)\n",
    "        \n",
    "        total_bp = sum(len(c) for c in contigs)\n",
    "        results.append({\n",
    "            'min_coverage': min_cov,\n",
    "            'num_contigs': len(contigs),\n",
    "            'total_bp': total_bp,\n",
    "            'avg_contig_size': total_bp / len(contigs) if contigs else 0\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "error_corr_results = analyze_error_correction_effect(test_reads_large[:500], k=21)\n",
    "\n",
    "print(\"Error Correction: Effect of Minimum K-mer Coverage Threshold\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Min Coverage':<15} {'Contigs':<12} {'Total BP':<15} {'Avg Contig Size'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for r in error_corr_results:\n",
    "    print(f\"{r['min_coverage']:<15} {r['num_contigs']:<12} {r['total_bp']:<15} {r['avg_contig_size']:.0f}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Higher thresholds remove more spurious k-mers (from errors)\")\n",
    "print(\"- But may also remove real low-coverage regions\")\n",
    "print(\"- Typical choice: min_coverage = 2-3 for diploid, 3-5 for haploid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dab1d3f",
   "metadata": {},
   "source": [
    "## 5. The Effect of K-mer Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a843af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_kmer_sizes(reads: List[str], k_values: List[int] = [15, 21, 31, 51]):\n",
    "    \"\"\"\n",
    "    Show how different k-mer sizes affect assembly quality.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for k in k_values:\n",
    "        assembler = DeBruijnAssembler(k=k)\n",
    "        contigs = assembler.assemble(reads, min_coverage=2)\n",
    "        \n",
    "        total_bp = sum(len(c) for c in contigs)\n",
    "        results.append({\n",
    "            'k': k,\n",
    "            'num_contigs': len(contigs),\n",
    "            'total_bp': total_bp,\n",
    "            'avg_contig_size': total_bp / len(contigs) if contigs else 0,\n",
    "            'longest_contig': max(len(c) for c in contigs) if contigs else 0\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "kmer_results = test_kmer_sizes(test_reads_large, k_values=[15, 21, 31, 51])\n",
    "\n",
    "print(\"\\nEffect of K-mer Size on Assembly Quality\")\n",
    "print(\"=\"*90)\n",
    "print(f\"{'K':<5} {'Contigs':<12} {'Total BP':<15} {'Avg Size':<12} {'Longest Contig'}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "for r in kmer_results:\n",
    "    print(f\"{r['k']:<5} {r['num_contigs']:<12} {r['total_bp']:<15} {r['avg_contig_size']:.0f}bp {r['longest_contig']:<14}bp\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Smaller k: More k-mers → more connections → longer contigs\")\n",
    "print(\"  BUT: More false connections at repeats\")\n",
    "print(\"\\n- Larger k: Fewer spurious connections → cleaner assembly\")\n",
    "print(\"  BUT: Sensitivity to errors (errors break reads into more k-mers)\")\n",
    "print(\"\\n- Best practice: Use k around L/√C where L=read length, C=coverage\")\n",
    "print(f\"\\n  For your reads (L≈{len(test_reads_large[0])}, C≈10): k ≈ {int(len(test_reads_large[0])/np.sqrt(10))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01857cfb",
   "metadata": {},
   "source": [
    "## 6. Handling Repeats: A Key Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b51c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Repeat Problem in Genome Assembly\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Create a genome with repeats\n",
    "repeat_unit = \"ATGCGATCGATCG\"\n",
    "unique1 = repeat_unit + \"TTTT\"\n",
    "repeat_region = repeat_unit * 3  # 3 copies of repeat\n",
    "unique2 = repeat_unit + \"GGGG\"\n",
    "repeat_genome = unique1 + repeat_region + unique2\n",
    "\n",
    "print(f\"Test genome with repeats:\")\n",
    "print(f\"  [Unique region 1]--[3x repeated unit]--[Unique region 2]\")\n",
    "print(f\"  Total length: {len(repeat_genome)} bp\\n\")\n",
    "\n",
    "# Generate reads\n",
    "repeat_reads = generate_reads_from_sequence(repeat_genome, read_length=100, coverage=15)\n",
    "\n",
    "print(f\"Generated {len(repeat_reads)} reads (15x coverage)\")\n",
    "print()\n",
    "\n",
    "# Assemble with different k-mer sizes\n",
    "print(\"Assembly results with different k-mer sizes:\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for k in [15, 21, 31]:\n",
    "    assembler = DeBruijnAssembler(k=k)\n",
    "    contigs = assembler.assemble(repeat_reads, min_coverage=3)\n",
    "    \n",
    "    print(f\"\\nk={k}:\")\n",
    "    print(f\"  Contigs: {len(contigs)}\")\n",
    "    for i, contig in enumerate(sorted(contigs, key=len, reverse=True)[:3]):\n",
    "        print(f\"    Contig {i+1}: {len(contig)} bp\")\n",
    "        # Check if it's from unique or repeat region\n",
    "        if contig in repeat_genome:\n",
    "            print(f\"             (matches unique region)\")\n",
    "        elif repeat_unit in contig:\n",
    "            count = contig.count(repeat_unit)\n",
    "            print(f\"             (contains {count}x repeat unit - ambiguous!)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Key insight: Repeats create branching in the graph!\")\n",
    "print(\"- Can't distinguish which path is correct without additional info\")\n",
    "print(\"- Solution: Use paired-end reads (next notebook!)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106b8aec",
   "metadata": {},
   "source": [
    "## 7. Summary and Algorithm Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8789b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_table = \"\"\"\n",
    "ALGORITHM COMPARISON\n",
    "═════════════════════════════════════════════════════════════════════════\n",
    "\n",
    "GREEDY OVERLAP-BASED ASSEMBLY\n",
    "─────────────────────────────────────────────────────────────────────────\n",
    "Algorithm:\n",
    "  1. Compare all pairs of reads/contigs\n",
    "  2. Find pair with best overlap\n",
    "  3. Merge them\n",
    "  4. Repeat until no more merges possible\n",
    "\n",
    "Time Complexity: O(n² × L²) where n=number of reads, L=read length\n",
    "Space Complexity: O(n)\n",
    "\n",
    "Pros:\n",
    "  ✓ Conceptually simple\n",
    "  ✓ Good for small genomes\n",
    "  ✓ No parameter tuning needed (besides min overlap)\n",
    "\n",
    "Cons:\n",
    "  ✗ Very slow for large genomes (n² comparisons)\n",
    "  ✗ Greedy decisions can produce suboptimal results\n",
    "  ✗ Can't resolve repeat regions\n",
    "  ✗ Sensitive to sequencing errors\n",
    "\n",
    "─────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "DE BRUIJN GRAPH ASSEMBLY\n",
    "─────────────────────────────────────────────────────────────────────────\n",
    "Algorithm:\n",
    "  1. Extract all k-mers from reads\n",
    "  2. Build graph: nodes=(k-1)-mers, edges=k-mers\n",
    "  3. Remove low-coverage k-mers (error correction)\n",
    "  4. Find Eulerian paths (contigs)\n",
    "\n",
    "Time Complexity: O(n × L) for graph building, O(n + m) for path finding\n",
    "  where n=number of reads, L=read length, m=number of k-mers\n",
    "Space Complexity: O(m) where m=number of unique k-mers\n",
    "\n",
    "Pros:\n",
    "  ✓ Much faster: linear in number of reads\n",
    "  ✓ Handles repeats explicitly (branching in graph)\n",
    "  ✓ Built-in error correction (k-mer frequency)\n",
    "  ✓ Scalable to large genomes\n",
    "  ✓ Used by modern assemblers (SPAdes, Velvet, etc.)\n",
    "\n",
    "Cons:\n",
    "  ✗ More complex to understand\n",
    "  ✗ Requires parameter tuning (k, min_coverage)\n",
    "  ✗ Still can't fully resolve ambiguous repeats\n",
    "  ✗ Higher memory usage for very large graphs\n",
    "\n",
    "─────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "MODERN ASSEMBLERS TYPICALLY:\n",
    "  • Use De Bruijn graphs with multiple k-mer sizes\n",
    "  • Apply graph simplification to remove errors and spurious nodes\n",
    "  • Use paired-end reads for disambiguation (see next notebook)\n",
    "  • Include polynomial time/space optimizations\n",
    "\n",
    "═════════════════════════════════════════════════════════════════════════\n",
    "\"\"\"\n",
    "\n",
    "print(comparison_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb90f95",
   "metadata": {},
   "source": [
    "## Real-World Tools Built on These Concepts\n",
    "\n",
    "**De Bruijn Graph Assemblers:**\n",
    "- **SPAdes** (most popular): Uses multiple k-mer sizes, graph simplification, paired-end reads\n",
    "- **Velvet**: Original De Bruijn graph assembler\n",
    "- **ABySS**: Parallel De Bruijn graph assembly\n",
    "\n",
    "**Other Approaches:**\n",
    "- **Overlap-Layout-Consensus (OLC)**: Used by long-read assemblers (PacBio, Oxford Nanopore)\n",
    "- **String Graph Assembly**: Improved OLC variant\n",
    "- **Hybrid Assemblers**: Combine short reads (De Bruijn) + long reads (OLC)\n",
    "\n",
    "**Installation & Use:**\n",
    "```bash\n",
    "# SPAdes (recommended for Illumina reads)\n",
    "conda install -c bioconda spades\n",
    "spades.py -1 reads_R1.fastq -2 reads_R2.fastq -o output_dir -k 21,33,55,77\n",
    "\n",
    "# Velvet\n",
    "conda install -c bioconda velvet\n",
    "velveth output_dir 21 -fastq reads.fastq\n",
    "velvetg output_dir\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf18938",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "**This notebook covered:**\n",
    "- ✓ Greedy overlap-based assembly (simple, slow)\n",
    "- ✓ De Bruijn graph assembly (modern, efficient)\n",
    "- ✓ Error correction via k-mer frequency\n",
    "- ✓ The effect of k-mer size and coverage thresholds\n",
    "- ✓ Why repeats are fundamentally challenging\n",
    "\n",
    "**Next notebook (4) will cover:**\n",
    "- Building contigs from graph paths\n",
    "- Using paired-end reads to resolve ambiguities\n",
    "- Scaffolding: linking contigs into larger structures\n",
    "- Gap filling\n",
    "- Output formats (FASTA)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
